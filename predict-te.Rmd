---
title: "Predict TE from the amount of missingness"
author: Trang Le
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "htmls") })
---
```{r setup}
source('R/utils.R')
required_pkgs <- c('tidyverse', 'lubridate', 'stm', 'RColorBrewer')
install_required(required_pkgs)

library(tidyverse)
library(lubridate)
library(stm)
library(RColorBrewer)
```

```{r warning=FALSE, message=FALSE}
my_dir <- "../4ce/Input"

theme_set(theme_bw() +
  theme(
    legend.title = element_blank(),
    panel.grid.minor = element_blank()
  ))
```

## Read in files 
and convert to wide format

```{R message=FALSE}

# 4CE long format Labs Data

patient_obs <- read_csv(file.path(my_dir, "LocalPatientObservations.csv"),
  col_types = list(patient_num = readr::col_character())
)

# Code, Descriptions and Ranges
lab_mapping <- read_csv("public-data/loinc-map.csv")
lab_bounds <- read_csv("public-data/lab_bounds.csv")
lab_names <- lab_bounds$short_name

#Read in local patient summary

demo_raw <-
  readr::read_csv(
    file.path(my_dir, "LocalPatientSummary.csv"),
    col_types = list(patient_num = readr::col_character()),
    na = "1900-01-01"
  ) %>%
  mutate(
    across(ends_with("_date") & where(is.character), lubridate::mdy),     
    last_discharge_date = if_else(
      !is.na(death_date) & death_date < last_discharge_date,
      death_date,
      last_discharge_date
    )
  )

data_dir <- "../4ce/Input/"
```

```{r}

#Read in thrombotic icd codes. Add column "truncated code" for first three characters of each code. Extract unique truncated codes.

thrombo_codes <- read_csv("https://raw.githubusercontent.com/covidclinical/Phase2.1AKIRPackage/ac19716a4586f45c398728fcd821ca9d5baffe45/FourCePhase2.1AKI/data-raw/thromb_icd_code.csv") %>%
  mutate(truncated_code = substr(icd_code, 1, 3)) %>%
  pull(truncated_code) %>%
  unique()
```


```{r}

#Isolate patients with thrombotic events and remove the days_since_admission column.

thrombo_patients <- patient_obs %>%
  filter(
    concept_type == "DIAG-ICD10",
    concept_code %in% thrombo_codes,
    days_since_admission >= 0
  ) %>%
  select(-days_since_admission) %>%
  distinct()

#Isolate information for unique patients. Sum individual patients with thrombotic events.

demo_df <- demo_raw %>%
  mutate(
    TE = patient_num %in% unique(thrombo_patients$patient_num),
    deceased = deceased == 1,
    severe = severe == 1
  )
demo_df$TE %>% sum()

#Generate a table that contains information about each lab for each individual patient. Each observation is identified by their patient number and days since admission, and each lab name and value is included. If there is more than one lab value for that identifier, they are averaged.

patient_obs_wide <- patient_obs %>%
  left_join(lab_bounds, by = c("concept_code" = "LOINC")) %>%
  select(-concept_code) %>%
  filter(!is.na(short_name)) %>% 
  pivot_wider(
    id_cols = c(patient_num, days_since_admission),
    names_from = short_name,
    values_from = value,
    values_fn = mean
  )
outcome <- "TE"
# outcome <- "deceased"
```

## Unsupervised learning: LDA

```{r}
upper_day <- 9
err_xgbs <- vector("numeric")
err_svms <- vector("numeric")
all_evals <- list()

#filter out observations with days since admission >= a threshold (upper_day, in this case 9 days) and days since admission  < 0. Take out the days_since_admission column. Obtain number of lab values for each TE patient.

missing_by_patient <- patient_obs_wide %>%
  filter(
    days_since_admission <= upper_day, # 10-day window
    days_since_admission >= 0
  ) %>%
  group_by(patient_num) %>%
  summarise(across(-days_since_admission, function(x) {
    sum(!is.na(x))
  })) %>%
  left_join(demo_df, by = "patient_num")

#Obtain total number of observations per lab for TE patients

uniq_vals <-
  apply(missing_by_patient, 2, function(x) {
    length(unique(x))
  })

#Isolate lab names

lab_names <-
  intersect(lab_bounds$short_name, names(missing_by_patient))

#Remove patients that have no lab values

missing_by_patient <- missing_by_patient[, uniq_vals > 1] %>%
  # mutate(outcome = as.factor(outcome)) %>%
  mutate(sum_labs = rowSums(across(all_of(lab_names)))) %>% 
  filter(sum_labs > 0)

#Reduce dataframe to matrix with labs and values

x_mat <- missing_by_patient[, lab_names]
```

```{r}
# set.seed(1)
# m <- topicmodels::LDA(x_mat, method = "Gibbs", k = 8,  control = list(alpha = 0.1))
```

```{r cache=TRUE}
exclusivity <- function(mod.out, M = 10, frexw = .7) {
  w <- frexw
  if (length(mod.out$beta$logbeta) != 1) stop("Exclusivity calculation only designed for models without content covariates")
  tbeta <- t(exp(mod.out$beta$logbeta[[1]]))
  s <- rowSums(tbeta)
  mat <- tbeta / s # normed by columns of beta now.

  ex <- apply(mat, 2, rank) / nrow(mat)
  fr <- apply(tbeta, 2, rank) / nrow(mat)
  frex <- 1 / (w / ex + (1 - w) / fr)
  index <- apply(tbeta, 2, order, decreasing = TRUE)[1:M, ]
  out <- vector(length = ncol(tbeta))
  for (i in 1:ncol(frex)) {
    out[i] <- sum(frex[index[, i], i])
  }
  out
}

x_dfm <- x_mat %>%
  rownames_to_column("id") %>%
  pivot_longer(-id, names_to = "lab", values_to = "n") %>%
  tidytext::cast_dfm(id, lab, n)
```


```{r cache=TRUE}

#Determine the optimal number of topics

system.time(many_models <- data.frame(K = seq(2, 8, 1)) %>%
  mutate(topic_model = furrr::future_map(K, ~ stm(
    x_dfm,
    K = .,
    seed = TRUE,
    verbose = FALSE
  ))))

heldout <- make.heldout(x_dfm)

k_result <- many_models %>%
  mutate(
    exclusivity = map(topic_model, exclusivity),
    semantic_coherence = map(topic_model, semanticCoherence, x_dfm),
    eval_heldout = map(topic_model, eval.heldout, heldout$missing),
    residual = map(topic_model, checkResiduals, x_dfm),
    bound = map_dbl(topic_model, function(x) max(x$convergence$bound)),
    lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
    lbound = bound + lfact,
    iterations = map_dbl(topic_model, function(x) length(x$convergence$bound))
  )

k_result %>%
  transmute(K,
    `Lower bound` = lbound,
    Residuals = map_dbl(residual, "dispersion"),
    `Semantic coherence` = map_dbl(semantic_coherence, mean),
    `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")
  ) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line() +
  geom_point() +
  guides(color = FALSE) +
  scale_x_continuous(breaks = seq(2, 12, 2)) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(
    x = "K (number of topics)",
    y = NULL,
    title = "Model diagnostics by number of topics",
    subtitle = "These diagnostics indicate that a good number of topics is 5"
  )
```

We want to: maximize likelihood, lower bound, semantic coherence and minimize residuals.
- https://scholar.harvard.edu/files/dtingley/files/multimod.pdf
- http://proceedings.mlr.press/v22/taddy12/taddy12.pdf

```{r}

#Estimate the structural topic model using semi-collapsed variational EM. 

K <- 5
stmfit <- stm(x_dfm, K = K, verbose = FALSE, init.type = "Spectral", seed = TRUE)
# plot.STM(stmfit,typeC="summary",xlim=c(0,0.1))
```

```{r}
# labelTopics(stmfit)
topicQuality(stmfit, documents = x_dfm)
```

The darker the colors, the more the presence of that lab values contribute to that topic.
```{r}

#Beta represents log probabilities of labs in topics. Generate heat map of probabilities for each lab. 

beta_mat <- exp(stmfit$beta$logbeta[[1]])
colnames(beta_mat) <- stmfit$vocab
rownames(beta_mat) <- paste("Topic", 1:K)
heatmap(t(beta_mat), Rowv = NA, Colv = NA, 
        col= colorRampPalette(brewer.pal(8, "Blues"))(25),
        main = "Unordered")
heatmap(t(beta_mat), main = "Ordered",
        col= colorRampPalette(brewer.pal(8, "Blues"))(25))
legend(x="topleft", legend=c("min", "ave", "max"), 
     fill=colorRampPalette(brewer.pal(8, "Blues"))(3))
save(all_evals, beta_mat, file = "results/beta_matrix.Rdata")
```

```{r}
theta <- stmfit$theta
lapply(1:K, function(x) cor.test(theta[, x], as.numeric(missing_by_patient$TE)))
```

```{r}

#See if a given topic is associated with TE

topic_df <- data.frame(theta, te = missing_by_patient$TE) %>% 
  pivot_longer(- te, names_to = 'topic') %>% 
  mutate(topic = gsub('X', 'Topic ', topic))

topic_df %>% 
  ggplot(aes(x = te, y = value)) +
  geom_boxplot(alpha = 0.2) +
  facet_wrap(~ topic, scales = 'free') +
  NULL
```

Significance by TE:
```{r}
topic_plots <- list()
anno_positions <- c(0.353, 0.05, 0.08, 0.08, 0.365)
for (i in (1:K)){
  topic_plots[[i]] <- topic_df %>% 
    filter(topic == paste('Topic', i)) %>% 
    ggplot(aes(x = te, y = value, color = te)) +
    stat_summary(fun.data = "mean_cl_boot", size = 1, stroke = 0.2, fatten = 1.5) +
    facet_wrap(~ topic, scales = 'free') +
    guides(color = FALSE) +
    ggpubr::stat_compare_means(label.y = anno_positions[i]) +
    labs(x = NULL, y = NULL) +
    NULL
}
cowplot::plot_grid(plotlist = topic_plots)
```

To get the interactive visualization, please uncomment the following lines,
Run All (not Knit).
Please share a screenshot of the result if possible!
You may have to install the tm package with `install.packages('tm')`.
```{r}
# x_docs = quanteda::convert(x_dfm, to = 'lda')
# toLDAvis(mod=stmfit, docs=x_docs$documents)
```

```{r}
beepr::beep()
```

```{r}
knitr::knit_exit()
```


